"""
RAG-—Å–∏—Å—Ç–µ–º–∞ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è Telegram-–±–æ—Ç–∞ –∫–æ—Ñ–µ–π–Ω–∏
–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—é, –ø–æ–∏—Å–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Ç–≤–µ—Ç–æ–≤
"""
import numpy as np
from sentence_transformers import SentenceTransformer
from openai import OpenAI
import os

class TZ_RAG_System:
    def __init__(self, index_file="index.npz", use_api=False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG-—Å–∏—Å—Ç–µ–º—ã
        
        Args:
            index_file: —Ñ–∞–π–ª —Å –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–º –¢–ó
            use_api: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ —Ä–µ–∞–ª—å–Ω—ã–π API (False –¥–ª—è –¥–µ–º–æ)
        """
        self.use_api = use_api
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –¢–ó
        z = np.load(index_file, allow_pickle=True)
        self.embs = z["embs"]
        self.texts = z["texts"].tolist()
        
        # –ú–æ–¥–µ–ª—å –¥–ª—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
        self.model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è API (–µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)
        if use_api:
            self.client = OpenAI(
                api_key=os.getenv('OPENAI_API_KEY', '–≤–∞—à_–∫–ª—é—á_–∑–¥–µ—Å—å'),
                base_url="https://api.deepseek.com"
            )
        
        print(f"‚úÖ RAG-—Å–∏—Å—Ç–µ–º–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –†–∞–∑–¥–µ–ª–æ–≤: {len(self.texts)}")
    
    def find_similar(self, query, top_k=3):
        """
        –ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ —Ä–∞–∑–¥–µ–ª—ã –¢–ó –ø–æ –∑–∞–ø—Ä–æ—Å—É
        
        Args:
            query: —Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞
            top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–∞—Ö
        """
        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
        query_emb = self.model.encode(
            query, 
            normalize_embeddings=True, 
            convert_to_numpy=True
        )
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = self.embs @ query_emb
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-K –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏—Ö
        top_indices = similarities.argsort()[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            chunk_text = self.texts[idx]
            lines = chunk_text.split('\n')
            title = lines[0] if lines else "–ë–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞"
            
            results.append({
                'index': int(idx),
                'similarity': float(similarities[idx]),
                'title': title,
                'content': chunk_text,
                'preview': chunk_text[:150] + "..."
            })
        
        return results
    
    def generate_answer(self, query, relevant_chunks):
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
        
        Args:
            query: –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            relevant_chunks: –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã
            
        Returns:
            –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "–ò–ù–§–û–†–ú–ê–¶–ò–Ø –ò–ó –¢–ï–•–ù–ò–ß–ï–°–ö–û–ì–û –ó–ê–î–ê–ù–ò–Ø:\n\n"
        for i, chunk in enumerate(relevant_chunks, 1):
            context += f"=== –†–ê–ó–î–ï–õ {i} ===\n"
            context += f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {chunk['title']}\n"
            context += f"–°—Ö–æ–¥—Å—Ç–≤–æ: {chunk['similarity']:.3f}\n"
            context += f"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\n{chunk['content'][:500]}...\n\n"
        
        # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π API
        if self.use_api and hasattr(self, 'client'):
            try:
                response = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[
                        {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –∑–∞–¥–∞–Ω–∏—é Telegram-–±–æ—Ç–∞ –∫–æ—Ñ–µ–π–Ω–∏. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."},
                        {"role": "user", "content": f"{context}\n\n–í–æ–ø—Ä–æ—Å: {query}"}
                    ],
                    max_tokens=500,
                    temperature=0.3
                )
                return response.choices[0].message.content
            except Exception as e:
                return f"–û—à–∏–±–∫–∞ API: {str(e)}\n\n{self._generate_local_answer(query, relevant_chunks)}"
        else:
            # –õ–æ–∫–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è (–¥–µ–º–æ-—Ä–µ–∂–∏–º)
            return self._generate_local_answer(query, relevant_chunks)
    
    def _generate_local_answer(self, query, relevant_chunks):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è API"""
        answer = f"–û–¢–í–ï–¢ –Ω–∞ –≤–æ–ø—Ä–æ—Å: '{query}'\n\n"
        answer += "–ù–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è:\n\n"
        
        for chunk in relevant_chunks:
            title = chunk['title']
            similarity = chunk['similarity']
            
            if similarity > 0.3:  # –¢–æ–ª—å–∫–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
                answer += f"üìÑ {title}\n"
                
                # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                content = chunk['content'].lower()
                
                if "–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å" in query.lower() or "–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å" in content:
                    answer += "‚Ä¢ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å –∫–Ω–æ–ø–∫–∞–º–∏: '–ú–µ–Ω—é', '–ö–æ—Ä–∑–∏–Ω–∞', '–ò—Å—Ç–æ—Ä–∏—è –∑–∞–∫–∞–∑–æ–≤', '–ê–∫—Ü–∏–∏'\n"
                    answer += "‚Ä¢ –ê–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–∏–≤–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤\n"
                    answer += "‚Ä¢ –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –ø–æ–Ω—è—Ç–Ω–∞—è –Ω–∞–≤–∏–≥–∞—Ü–∏—è\n\n"
                
                elif "–æ–ø–ª–∞—Ç" in query.lower() or "–æ–ø–ª–∞—Ç" in content:
                    answer += "‚Ä¢ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è QR-–∫–æ–¥–∞ –¥–ª—è –æ–ø–ª–∞—Ç—ã\n"
                    answer += "‚Ä¢ –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—à–Ω–æ–π –æ–ø–ª–∞—Ç–µ\n"
                    answer += "‚Ä¢ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø–ª–∞—Ç–µ–∂–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π\n\n"
                
                elif "—Ñ—É–Ω–∫—Ü–∏" in query.lower() or "—Ñ—É–Ω–∫—Ü–∏" in content:
                    answer += "‚Ä¢ –ú–µ–Ω—é —Ç–æ–≤–∞—Ä–æ–≤ —Å —Ü–µ–Ω–∞–º–∏\n"
                    answer += "‚Ä¢ –ö–æ—Ä–∑–∏–Ω–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ —Ç–æ–≤–∞—Ä–æ–≤\n"
                    answer += "‚Ä¢ –ò—Å—Ç–æ—Ä–∏—è –∑–∞–∫–∞–∑–æ–≤ –∏ —Å—Ç–∞—Ç—É—Å—ã\n\n"
                
                else:
                    # –û–±—â–∏–π –æ—Ç–≤–µ—Ç
                    answer += f"‚Ä¢ –°–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ —Ä–∞–∑–¥–µ–ª–µ '{title}'\n"
                    answer += f"‚Ä¢ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.3f}\n\n"
        
        if len(answer.split('\n')) < 10:  # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
            answer += "\nüí° –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —É—Ç–æ—á–Ω–∏—Ç–µ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–∞–ª—å–Ω—ã–π API –∫–ª—é—á."
        
        return answer
    
    def ask(self, query, top_k=3):
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –∫ —Å–∏—Å—Ç–µ–º–µ
        
        Args:
            query: –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            top_k: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        """
        print(f"\n{'='*60}")
        print(f"‚ùì –í–û–ü–†–û–°: {query}")
        print('='*60)
        
        # 1. –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤
        print("\nüîç –ü–æ–∏—Å–∫ –≤ –¢–ó...")
        relevant_chunks = self.find_similar(query, top_k)
        
        # 2. –í—ã–≤–æ–¥ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ
        print(f"\nüìö –ù–∞–π–¥–µ–Ω–æ {len(relevant_chunks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤:")
        for i, chunk in enumerate(relevant_chunks, 1):
            print(f"{i}. [{chunk['index']}] {chunk['title'][:50]}... (—Å—Ö–æ–¥—Å—Ç–≤–æ: {chunk['similarity']:.3f})")
        
        # 3. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        print("\nü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
        answer = self.generate_answer(query, relevant_chunks)
        
        # 4. –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        print(f"\n{'='*60}")
        print("üí° –û–¢–í–ï–¢:")
        print('='*60)
        print(answer)
        
        return {
            'query': query,
            'relevant_chunks': relevant_chunks,
            'answer': answer
        }

def demo():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã"""
    print("üöÄ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø RAG-–°–ò–°–¢–ï–ú–´")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ —Å –≤–µ–∫—Ç–æ—Ä–∞–º–∏
    if not os.path.exists("index.npz"):
        print("‚ùå –§–∞–π–ª index.npz –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        print("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ: python md_to_vectors.py TZ.md")
        return
    
    # –°–æ–∑–¥–∞–µ–º —Å–∏—Å—Ç–µ–º—É
    rag = TZ_RAG_System("index.npz", use_api=False)
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "–ö–∞–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É –±–æ—Ç–∞?",
        "–ö–∞–∫ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –æ–ø–ª–∞—Ç–∞ –∑–∞–∫–∞–∑–∞?",
        "–ö–∞–∫–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É –±–æ—Ç–∞?",
        "–ö–∞–∫–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –Ω—É–∂–Ω—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞?"
    ]
    
    for query in test_queries[:2]:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 2 –∑–∞–ø—Ä–æ—Å–∞
        result = rag.ask(query, top_k=2)
        print("\n" + "="*60 + "\n")

if __name__ == "__main__":
    demo()
